\documentclass[10pt]{beamer}
\usefonttheme[onlymath]{serif}
\usepackage{mathpazo}
\usepackage{tikz}
\setbeamertemplate{footline}[frame number]
\setbeamertemplate{caption}[numbered]
\usepackage{ragged2e}
\usepackage{enumerate}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage[autoplay,loop]{animate}
\renewcommand{\raggedright}{\leftskip=0pt \rightskip=0pt plus 0cm}
%%\setbeamertemplate{navigation sybols}{}
\author{LIU. Ruiwu}
\institute{the Department of Economic Engineering\\Kyushu University}
\date{2024}
\title{DSGE Model \uppercase\expandafter{\romannumeral1}}
\subtitle{An Introduction to Stochastic Dynamic
Programming}
%% Title Page
\begin{document}
%% Outline
	\frame{\titlepage}
	\begin{frame}[c]\frametitle{Outline}
	\tableofcontents
	\end{frame}
%% 3 Page
	\begin{frame}[c]\frametitle{Introduction}
		\section{Introduction}
\raggedright
	\begin{itemize}
\item Stochastic growth models are useful for two related reasons.
\begin{itemize}
    \item A range of interesting growth problems involve either aggregate
uncertainty or nontrivial individual-level uncertainty interacting with investment decisions and
the growth process.
\item The stochastic
neoclassical growth model has a wide range of applications in macroeconomics and in other
areas of dynamic economic analysis.
\end{itemize}
		\item Before the baseline neoclassical growth model
(with complete markets) augmented with stochastic productivity shocks (Brock and Mirman (1972)),
\begin{itemize}
    \item Which is not only an important generalization of the baseline
neoclassical growth, but also provides the starting point of the influential \textbf{Real
Business Cycle} models, which are used extensively for the study of a range of short- and
medium-run macroeconomic questions.
\end{itemize}
\item It's necessary to learn how to program the stochastic dynamic.
\item We use \textbf{Markov Chains} to represent uncertainty.
	\end{itemize}
	\end{frame}
%%% 4 Page
\begin{frame}[c]\frametitle{Stochastic Dynamic
Programming}
	\section{Stochastic Dynamic
Programming}
	\subsection{Dynamic Programming with Expectations}
		\raggedright
	\begin{block}{\textbf{Dynamic Programming with Expectations}}
			\begin{itemize}
    		\item Let us first introduce the \textit{stochastic} (random) variable \( z(t) \in \mathcal{Z} \equiv \{z_1, \ldots, z_N\} \), with \( z_1 < z_2 < \cdots < z_N \). Note that the set \( \mathcal{Z} \) is finite and thus compact. Let the instantaneous payoff at time \( t \) be
\[
U(x(t), x(t+1), z(t)) \eqno{(1)}
\]
where \( x(t) \in X \subset \mathbb{R}^K \) for some \( K \geq 1 \) and \( U: X \times X \times \mathcal{Z} \to \mathbb{R} \). 
\item Payoffs: a function of the stochastic variable \( z(t) \). 
\item As usual, returns are discounted by some discount factor \( \beta \in (0, 1) \).
\item \( x(t) \) denotes the \textit{state variables} (state vector), and \( x(t+1) \) the \textit{control variables} (control vector) at time \( t \). 
\item The initial values of the state vector, \( x(0) \), and of stochastic variable, \( z(0) \), are taken as given.
	\end{itemize}
\end{block}
\end{frame}
%% 5rd Page
\begin{frame}[c]\frametitle{Cont.}
	\raggedright
\begin{itemize}
	\item The constraint also incorporates the stochastic variable \( z(t) \) and is written as
 \[
x(t+1) = G(x(t), z(t))
\]
where \( G(x, z) \) is a set-valued mapping (correspondence):
\[
G : X \times \mathcal{Z} \rightrightarrows X
\]
	\item Suppose that the stochastic variable \( z(t) \) follows a (first-order) \textit{\textbf{Markov chain}}. The important property implied by the Markov chain assumption is that the current value of \( z(t) \) only depends on its value from the last period, \( z(t-1) \). Mathematically, this can be expressed as
\[
\Pr[z(t) = z_j \mid z(0), \ldots, z(t-1)] = \Pr[z(t) = z_j \mid z(t-1)]
\]
\end{itemize}
\end{frame}
%%6
\begin{frame}[c]\frametitle{Cont.}
\raggedright
\begin{itemize}
	\item The Markov property not only simplifies the mathematical structure of economic models but
also allows us to use relatively simple notation for the probability distribution of the random
variable $z(t)$. We can also represent a Markov chain as
\[
\Pr[z(t) = z_j \mid z(t-1) = z_{j^{'}}] \equiv q_{jj^{'}}
\]
For any $j, j' = 1, \ldots, N$, where $q_{ij} \geq 0$ for all $j, j'$, and
\[
\sum_{j=1}^N q_{jj^{'}} = 1 \quad \text{for each } j' = 1, \ldots, N.
\]
\item $q_{jj^{'}}$ is also referred to as a \textit{transition probability}, meaning the probability of the stochastic state $z$ transitioning from $z_{j^{'}}$ to $z_j$.
\end{itemize}
\end{frame}
%%% 7th Page
\begin{frame}[c]\frametitle{An Example}
\subsection{Example}
\raggedright
\textit{Recall the optimal growth problem, where the objective is to maximize}
\[
\mathbb{E}_0 \sum_{t=0}^\infty \beta^t u(c(t)).
\]
\textit{The expectations operator $\mathbb{E}_0$ stands for expectations conditional on information available at (the beginning of) time $t = 0$.}
\\
\quad \\
\textit{Expectations are necessary here
because the future values of consumption per capita are stochastic (as they depend on the
realizations of future $z$ values).}
\end{frame}
%%% 8th Page
\begin{frame}[c]\frametitle{Cont.}
\raggedright
\begin{itemize}
	\item The production function:\[
y(t) = f(k(t), z(t))
\]
	\item The most natural interpretation of $z(t)$ in this context is as a stochastic \textbf{TFP} term.
	\item  The resource constraint:
 \[
k(t + 1) = f(k(t), z(t)) + (1 - \delta)k(t) - c(t) \eqno{(2)}
\]
It implies that when $c(t)$ is chosen, the random variable $z(t)$
has been realized. Thus $c(t)$ depends on the realization of $z(t)$, and in fact on the entire history of $z(t)$.
	\item We define
 \[
z^t \equiv (z(1), \ldots, z(t))
\]
as the history of $z(t)$ up to date $t$. As a convention, this history does not include $z(0)$, which is taken as given, to ensure $z^t$ has $t$ elements.
\end{itemize}
\end{frame}
%% 9
\begin{frame}[c]\frametitle{Cont.}
\raggedright
		\begin{itemize}
			\item 	In particular, let $
\mathcal{Z}^t = \mathcal{Z} \times \cdots \times \mathcal{Z}$ (the t-times product), so that $z^t \in \mathcal{Z}^t$.
			\item For given $k(0)$, the consumption at time $t$ can be  written as
\[
c(t) = \tilde{c}[z^t]
\]
which states that consumption at time $t$ is a function of the entire sequence of
random variables observed up to that point.
			\item In terms of (1), here $x(t) = k(t)$, so that
   \begin{align*}
x(t + 1) &= k(t + 1) \\
         &= f(k(t), z(t)) + (1 - \delta)k(t) - \tilde{c}[z^t] \\
         & \equiv \tilde{k}[z^t]
\end{align*}
by definition, $k(t+1)$ depends only on the history of the stochastic shocks up to time $t$ and not on $z(t
+ 1)$.
		\end{itemize}
\end{frame}
%%% 10th Page
\begin{frame}[c]\frametitle{Cont.}
	\raggedright
\begin{itemize}
	\item In addition, from the resource constraint we have:
 \[
\tilde{k}[z^t] = f(\tilde{k}[z^{t-1}], z(t)) + (1 - \delta)\tilde{k}[z^{t-1}] - \tilde{c}[z^t] \eqno{(3)}
\]
for all $z^{t-1} \in \mathcal{Z}^{t-1} \text{ and } z(t) \in \mathcal{Z}.$
	\item The maximization problem can then be expressed as:
 \[
\max_{\{\tilde{c}[z^t],\tilde{k}[z^t]\}_{t=0}^\infty} \mathbb{E}_0 \sum_{t=0}^\infty \beta^t u(\tilde{c}[z^t])
\]
subject to (3), $\tilde{c}[z^t] \geq 0$ and $\tilde{k}[z^t] \geq 0$ and starting
with the initial conditions $\tilde{k}[z^{-1}] = k(0)$ and $z(0)$.
\end{itemize}
\end{frame}
%%% 11th Page
\begin{frame}[c]\frametitle{Cont.}
	\raggedright
\begin{itemize}
	\item This maximization problem can also be
written using the instantaneous payoff function $U(x(t), x(t + 1), z(t))$ introduced in (1). Then, the maximization problem takes the form
\[
\max_{\{\tilde{k}[z^t]\}_{t=0}^\infty} \mathbb{E}_t \sum_{t=0}^\infty \beta^t U(\tilde{k}[z'^{t-1}], \tilde{k}[z^t], z(t)) \eqno(4)
\]
where we have $$
U(\tilde{k}[z'^{t-1}], \tilde{k}[z^t], z(t)) = u\left(f(k(t), z(t)) - k(t + 1) + (1 - \delta)k(t)\right)
$$
\item This example can also be used to show how the same maximization problem can be
represented recursively.
\end{itemize}
\end{frame}
%%% 12th Page
\begin{frame}[c]\frametitle{Cont.}
	\raggedright
	\begin{itemize}
		\item Since $z(t)$ follows a Markov chain, the current value of $z(t)$ contains
both information about the available resources for consumption and future capital stock and
information regarding the stochastic distribution of $z(t + 1)$. Thus we might naturally expect
the policy function determining the capital stock at the next date to take the form
\[
k(t + 1) = \pi(k(t), z(t))\eqno(5)
\]
\item The recursive characterization would take the form \small
\[
V(k, z) = \sup_{y \in [0, f(k,z) + (1-\delta)k]} \left\{ u(f(k, z) + (1 - \delta)k - y) + \beta \mathbb{E}[V(y, z^{'}) \mid z] \right\} \eqno(6) \]
\\
This expectation is different from that in (4). In (4), the expectation is over the entire set of future values of $z$, whereas in $(6)$, it is over next period’s value of $z, z^{'}$.
\end{itemize}
\end{frame}
%% 13
\begin{frame}[c]\frametitle{Solution}
	\subsection{Solution}
	\raggedright
 \normalsize
\begin{itemize}
	\item Let us suppose that this program has a solution, meaning that there exists a feasible plan that achieves the value $V(k, z)$ starting with capital-labor ratio $k$ and stochastic variable $z$.
 \item Then the set of the next date’s capital stock that achieves this maximum value can be represented by a correspondence $
\Pi(k, z)$ for $k \in \mathbb{R}_+$, and $z \in \mathcal{Z}$. For any $
\pi(k, z) \in \Pi(k, z)$, we have
\[
V(k, z) = u(f(k, z) + (1 - \delta)k - \pi(k, z)) + \beta \mathbb{E}[V(\pi(k, z), z') \mid z]
\]
When the correspondence $\Pi(k, z)$ is single valued, then $\pi(k, z)$ is uniquely defined and the
optimal choice of next period’s capital stock can be represented as in (5).
\item \textbf{This example indicates how a stochastic optimization problem can be written in
sequence form and also gives us a hint about how to express such a problem recursively.}
\end{itemize}
\end{frame}
%%%14
\begin{frame}[c]\frametitle{Problem 1}
\subsection{Problems}
	\raggedright
\begin{itemize}
	\item Let's do this more systematically.
	\item Let a \textbf{plan} be denoted by $\tilde{x}[z^t]$. It specifies the value of the vector $x \in \mathbb{R}^K$ for time $t + 1$  (i.e., $x(t + 1) = \tilde{x}[z^t]$) for any $z^t \in \mathcal{Z}^t$. The sequence problem takes the form\\
 \textbf{Problem 1}
\[
V^*(x(0), z(0)) = \sup_{\{\tilde{x}[z^t]\}_{t=0}^\infty} \mathbb{E}_0 \sum_{t=0}^\infty \beta^t U(\tilde{x}[z^{t-1}], \tilde{x}[z^t], z(t))
\]
subject to
\[
\tilde{x}[z^t] \in G(\tilde{x}[z^{t-1}], z(t)) \quad \text{for all } t \geq 0,
\]

\[
\tilde{x}[z^{-1}] = x(0) \text{ given}.
\]
\end{itemize}
\end{frame}
%%15
\begin{frame}[c]\frametitle{Problem 2}
\raggedright
\begin{itemize}
	\item  \textbf{Problem 2}\\Similar to (6) in our first example, the functional equation corresponding to the recursive formulation of this problem can be written as follows.
\[
V(x, z) = \sup_{y \in G(x,z)} \left\{ U(x, y, z) + \beta \mathbb{E}[V(y, z') \mid z] \right\} \eqno (7)
\]
for all $ x \in X $ and $z \in \mathcal{Z}$.
\item Here \( V : X \times \mathcal{Z} \to \mathbb{R} \) is a real-valued function, and \( y \in G(x, z) \) represents the constraint on next period's state vector as a function of the realization of the stochastic variable \( z \). 
\end{itemize}
\end{frame}
%%%16
\begin{frame}[c]\frametitle{Cont.}
	\raggedright
	\begin{itemize}
		\item let us first introduce the set of feasible plans starting with an initial value $x(t)$ and a value of the stochastic variable $z(t)$ as
  \small
  \[
\Phi(x(t), z(t)) = \{ \{\tilde{x}[z^s]\}_{s=t}^\infty : \tilde{x}[z^s] \in G(\tilde{x}[z^{s-1}], z(s)) \quad \text{for } s = t, t + 1, \ldots \}
\]
We denote a generic element of $\Phi(x(0), z(0))$ by $\mathbf{x} \equiv \{\tilde{x}[z^t]\}_{t=0}^\infty$.
\item We are interested in using the formulation in \textit{Problem 2} to characterize the solution to \textit{Problem 1}; thus we will investigate \textbf{I. when the solution $V(x, z)$ to \textit{Problem 2} coincides with the solution $V^{*}(x, z)$} and \textbf{II. when the set of maximizing plans $\Pi(x, z) \subset \Phi(x, z)$ also generates an optimal feasible plan for Problem 1} (presuming that
both problems have feasible plans attaining their supremums).
	\end{itemize}
\end{frame}
%%%%%%%%17
\begin{frame}[c]\frametitle{Cont.}
\raggedright
\begin{itemize}
	\item  Recall that the set of maximizing plans $\Pi(x, z)$ is defined such that for any $\pi(x, z) \in \Pi(x, z)$,
 \[
V(x, z) = U(x, \pi(x, z), z) + \beta \mathbb{E}[V(\pi(x, z), z') \mid z] \eqno(8)
\]
\end{itemize}
\end{frame}
%%%%%%%%18
\begin{frame}[c]\frametitle{Assumptions and Theorems}
\subsection{Assumptions and Theorems}
		\raggedright
\begin{block}{Assumptions 1}
\raggedright
    The correspondence \( G(x, z) \) is nonempty-valued for all \( x \in X \) and \( z \in \mathcal{Z} \). Moreover, for all \( x(0) \in X \), \( z(0) \in \mathcal{Z} \), and \(\mathbf{x} \in \Phi(x(0), z(0))\), the limit of expected discounted utility 
\[
\lim_{n \to \infty} \mathbb{E}\left[\sum_{t=0}^n \beta^t U(\tilde{x}[z^{t-1}], \tilde{x}[z^t], z(t)) \mid z(0)\right]
\]
exists and is finite.
\end{block}
\end{frame}
%%%%%%%%19
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
\begin{block}{Assumptions 2}
\raggedright
    \( X \) is a compact subset of \( \mathbb{R}^K \), and \( G \) is nonempty-valued, compact-valued, and continuous. Moreover, let \( X_G = \{(x, y, z) \in X \times X \times \mathcal{Z} : y \in G(x, z)\} \), and suppose that \( U : X_G \to \mathbb{R} \) is continuous.
\end{block}
\end{frame}
%%%%%%%%20
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
\begin{block}{Theorem 1}
\raggedright
    \textbf{(Equivalence of Values)} Suppose Assumptions 1 hold. Then for any \( x \in X \) and any \( z \in \mathcal{Z} \), \( V^*(x, z) \) that is a solution to \textit{Problem 1} is also a solution to \textit{Problem 2}. Moreover, any solution \( V(x, z) \) to \textit{Problem 2} is also a solution to \textit{Problem 1}, so that \( V^*(x, z) = V(x, z) \) for any \( x \in X \) and any \( z \in \mathcal{Z} \).
\end{block}
\begin{block}{Theorem 2}
\raggedright
    \textbf{(Principle of Optimality)} Suppose \textit{Assumptions 1} hold. For \( x(0) \in X \) and \( z(0) \in \mathcal{Z} \), let \( \mathbf{x}^* \equiv \{\tilde{x}^*[z^t]\}_{t=0}^\infty \in \Phi(x(0), z(0)) \) be a feasible plan that attains \( V^*(x(0), z(0)) \) in \textit{Problem 1}. Then we have
    \small
\[
V^*(\tilde{x}^*[z^{t-1}], z(t)) = U(\tilde{x}^*[z^{t-1}], \tilde{x}^*[z^t], z(t)) + \beta \mathbb{E}[V^*(\tilde{x}^*[z^t], z(t+1)) \mid z(t)] \quad (9)
\]
for \( t = 0, 1, \ldots \).\\
\normalsize
\quad 
\\Moreover, if \( \mathbf{x}^* \in \Phi(x(0), z(0)) \) satisfies (9), then it attains the optimal value for \textit{Problem 1}.
\end{block}
\end{frame}
%%%%%%%%21
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
\begin{block}{Theorem 3}
\raggedright
    \textbf{(Existence of Solutions)} Suppose that \textit{Assumptions 1 and 2} hold. Then there exists a unique function \( V : X \times \mathcal{Z} \to \mathbb{R} \) that satisfies (7). This function \( V \) is continuous and bounded in \( x \) for each \( z \in \mathcal{Z} \). Moreover, an optimal plan \( \mathbf{x}^* \in \Phi(x(0), z(0)) \) exists for any \( x(0) \in X \) and any \( z(0) \in \mathcal{Z} \).
\end{block}
\quad \\
The remaining results, as in their analogues in the \textbf{Neoclassical} Models, use further assumptions to establish \textit{concavity}, \textit{monotonicity}, and the \textit{differentiability} of the value function.
\end{frame}
%%%%%%%%22
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
\begin{block}{Assumption 3}
\raggedright
    \( U \) is concave. That is, for any \( \alpha \in (0, 1) \) and any \( (x, y, z) \) and \( (x', y', z) \) in \( X_G \), we have
\[
U(\alpha x + (1 - \alpha)x', \alpha y + (1 - \alpha)y', z) \geq \alpha U(x, y, z) + (1 - \alpha)U(x', y', z).
\]
Moreover, if \( x \neq x' \), then
\[
U(\alpha x + (1 - \alpha)x', \alpha y + (1 - \alpha)y', z) > \alpha U(x, y, z) + (1 - \alpha)U(x', y', z).
\]
In addition, \( G(x, z) \) is convex in \( x \). That is, for any \( z \in \mathcal{Z} \), any \( \alpha \in [0, 1] \), and any \( x, x', y, y' \in X \) such that \( y \in G(x, z) \) and \( y' \in G(x', z) \), we have
\[
\alpha y + (1 - \alpha) y' \in G(\alpha x + (1 - \alpha) x', z).
\]
\end{block}
\end{frame}
%%%%%%%%23
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
\begin{block}{Assumption 4}
\raggedright
   For each \( y \in X \) and \( z \in \mathcal{Z} \), \( U(\cdot, y, z) \) is strictly increasing in its first \( K \) arguments, and \( G \) is monotone in \( x \) in the sense that \( x \leq x' \) implies \( G(x, z) \subset G(x', z) \) for each \( z \in \mathcal{Z} \).
\end{block}
\begin{block}{Assumption 5}
\raggedright
\( U(x, y, z) \) is continuously differentiable in \( x \) in the interior of its domain \( X_G \).
\end{block}
\begin{block}{Theorem 4}
\raggedright
\textbf{(Concavity of the Value Function)} Suppose that \textit{Assumptions 1–3} hold. Then the unique function \( V \) that satisfies (7) is strictly concave in \( x \) for each \( z \in \mathcal{Z} \). Moreover, the optimal plan can be expressed as \( \tilde{x}^*[z^t] = \pi(x^*(t), z(t)) \), where the policy function \( \pi : X \times \mathcal{Z} \to X \) is continuous.
\end{block}
\end{frame}
%%%%%%%%24
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
\begin{block}{Theorem 5}
\raggedright
   \textbf{(Monotonicity of the Value Function I)} Suppose that Assumptions 1, 2, and 4 hold, and let \( V : X \times \mathcal{Z} \to \mathbb{R} \) be the unique solution to (7). Then for each \( z \in \mathcal{Z} \), \( V \) is strictly increasing in \( x \).
\end{block}
\begin{block}{Theorem 6}
\raggedright
\textbf{(Differentiability of the Value Function)} Suppose that \textit{Assumptions 1 2 3 5} hold. Let \( \pi \) be the policy function defined above and assume that \( x' \in \text{Int } X \) and \( \pi(x', z) \in \text{Int } G(x', z) \) at \( z \in \mathcal{Z} \). Then \( V(x, z) \) is continuously differentiable at \( (x', z) \) with the gradient with respect to \( x \) given by
\[
D_x V(x', z) = D_x U(x', \pi(x', z), z). \eqno(10)
\]
\end{block}
\end{frame}
%%%%%%%%25
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
  Above theorems have exact analogues in the Neoclassical programming. Since the value function now depends
on the stochastic variable $z$, an additional \textit{monotonicity} result can also be obtained. To do this, let us introduce the following assumption:
\begin{block}{Assumption 6}
\raggedright
\begin{enumerate}
    \item \( G \) is monotone in \( z \) in the sense that \( z \leq z' \) implies \( G(x, z) \subseteq G(x, z') \) for each \( x \in X \) and \( z, z' \in \mathcal{Z} \) such that \( z \leq z' \).
    \item For each \( (x, y, z) \in X_G \), \( U(x, y, z) \) is strictly increasing in \( z \).
    \item The Markov chain for \( z \) is monotone in the sense that for any nondecreasing function \( f : \mathcal{Z} \to \mathbb{R} \), \( \mathbb{E}[f(z') \mid z] \) is also nondecreasing in \( z \) (where \( z' \) is next period's value of \( z \)).
\end{enumerate}
\end{block}
\end{frame}
%%%%%%%%26
\begin{frame}[c]\frametitle{Cont.}
		\raggedright
\begin{block}{Theorem 7}
\raggedright
   \textbf{(Monotonicity of the Value Function II)} Suppose that \textit{Assumptions 1 2 6} hold, and let \( V : X \times \mathcal{Z} \to \mathbb{R} \) be the unique solution to (7). Then for each \( x \in X \), \( V \) is strictly increasing in \( z \).
\end{block}
\end{frame}
%%%%%%%
\begin{frame}[plain]
\begin{center}
	\textbf{	Thank You!}
\end{center}
	\end{frame}
\end{document} 
